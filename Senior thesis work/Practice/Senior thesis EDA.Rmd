---
title: "Senior thesis"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
library(igraph)
library(RSiena)
library(ggplot2)
library(network)
library(intergraph)
library(sna)
```

```{r}
#hh_hhh,gender,friendship,well-being (Covariates of interest). Receive grade data later.
#check question survey to understand. If not on notebook, use intuition
#Ignore wellbeing11,21

vdb.CoreGossip <- load("/Users/joonghochoi/Desktop/Senior thesis work/Data-Josh/CoreGossip/14100Nynke.RData")
vdb.CoreGossip
```
#hh_hhh=(measurement of low SES / highly disadvantaged status)
#well-being: continuous like grade. Focus on that
#roma: minority group in Hungary 
#kerdesek: ? 

```{r}
#vdb.GossipBully<-load("/Users/joonghochoi/Desktop/Senior thesis work/Data-Josh/GossipBully/14100Nynke.RData")
#vdb.GossipBully
```


```{r}
length(friendship)
dim(friendship[[1]])
dim(friendship[[2]])
#start off with one class data that has a lot of students who are not missing. 
#ex:14100=class. 14101,02,03.... are students. Ignore the rating they gave to themselves. 
#Do binary conversion for friendship variable 
#1-3 into 0 and 4-5 into 1.0 is not a tie and 10 is missing(NA).
```

```{r}
friendshipPreProcess <- function (item){
  #takes in friendship for all six waves and return preprocessed friendship
  len<-length(item)
  for (ii in 1:len){
    intermediate<-item[[ii]]
    k<-data.frame(intermediate)
    k[k <4]<-0
    k[k ==10]<-NA
    k[k>=4]<-1
    
    k[is.na(k)]<-0
    diag(k) <- 0
    item[[ii]]<-k
  }
  item
}
```

```{r}
res<-friendshipPreProcess(friendship)
for (ii in 1:6){
  f1<-as.matrix(as.data.frame(res[1])) #wave 1
  f2<-as.matrix(as.data.frame(res[2]))
  f3<-as.matrix(as.data.frame(res[3]))
  f4<-as.matrix(as.data.frame(res[4]))
  f5<-as.matrix(as.data.frame(res[5]))
  f6<-as.matrix(as.data.frame(res[6]))
}
```

colSums(kk) to see the indegree of kk and rowSums(kk) to see the outdegree of kk
```{r}
#Use this chunk if making assumption that loners or ppl who didn't answer survey will remain the same
removeLoners <- function (mat){
  i <- (colSums(f1, na.rm=T) != 0) # T if colSum is not 0, F otherwise
  j <- (rowSums(f1, na.rm=T) != 0) # T if colSum is not 0, F otherwise
  m<-c(i|j)
  m1<-sapply(m, as.numeric)
  m2<- which(m1 %in%0 )
  mat<-mat[-m2,-m2]
  mat
}
f1_1<-removeLoners(f1)
f2_1<-removeLoners(f2)
f3_1<-removeLoners(f3)
f4_1<-removeLoners(f4)
f5_1<-removeLoners(f5)
f6_1<-removeLoners(f6)
```

```{r}
#Use this chunk if don't want to make assumption that loners or ppl who didn't answer survey will remain the same

IdentifyLoners <- function (mat){
  i <- (colSums(f1, na.rm=T) != 0) # T if colSum is not 0, F otherwise
  j <- (rowSums(f1, na.rm=T) != 0) # T if colSum is not 0, F otherwise
  m<-c(i|j)
  m1<-sapply(m, as.numeric)
  m2<- which(m1 %in%0 )
  m2
}
L1<-IdentifyLoners(f1)
L2<-IdentifyLoners(f2)
L3<-IdentifyLoners(f3)
L4<-IdentifyLoners(f4)
L5<-IdentifyLoners(f5)
L6<-IdentifyLoners(f6)
m2<-Reduce(intersect, list(L1,L2,L3))
f1_1<-f1[-m2,-m2]
f2_1<-f2[-m2,-m2]
f3_1<-f3[-m2,-m2]
f4_1<-f4[-m2,-m2]
f5_1<-f5[-m2,-m2]
f6_1<-f6[-m2,-m2]

```

#Jaccard Index: to track how much network changes. 
number of ties that appear in both network/ number of ties that appear in either of them 

```{r}
jaccard_index<-function(g1,g2) {
  library(igraph)
  g1<-get.adjacency(g1)
  g1[g1 > 0.001] <- 1
  g2<-get.adjacency(g2)
  g2[g2 > 0.001] <- 1
  A<-sum(g1 != g2) # edges that changed (0->1 and 1->0)
  B<-sum(g1 * g2) # edges that have a 1 in M1 and 1 in M2, so stayed the same (1->1)
  return(round(B/sum(A,B),digits = 2)) # the ratio of stable ties ties (B), compared to all ties who change (A) + stable ties (B)
  on.exit(rm(A,B))
}
```


```{r}
set.seed(123)
g1<-graph_from_adjacency_matrix(f1_1)
plot(g1)
reciprocity(g1) # % of existing ties are reciprocated
diameter(g1)
```

```{r}
g2<-graph_from_adjacency_matrix(f2_1)
plot(g2)
reciprocity(g2) # % of existing ties are reciprocated
diameter(g2)
```

```{r}

jaccard_index(g1,g2)

```

#Making the friendship network with well being

```{r}
#1 male, 2 female
k2<-c(gender$gndr)
k2<-k2[-m2]
sex<-coCovar(k2)
sex
```

```{r}
#sienadependent for friendship, 32x32x6
#6 adjacent matrixes
friends <- sienaDependent(array(c(f1_1,f2_1,f3_1,f4_1,f5_1,f6_1),
                            dim=c(21,21,6)), allowOnly=TRUE)
```

#Note:
For behaviour Siena variable, we need matrix type object before normalizing and throwing in type. 
wellbeing 1: Average of wellbeing11-61
wellbeing11-61: 6 questions about wellbeing in wave 1 .
```{r}
#matrix where rows=student number and columns=time wave. Each box would show the average value of wellbeing 1-6. 
res1<-as.matrix(wellbeing[,2:7])
res1<-res1[-m2,]
#Network of friendship with well-being for RSiena.
welfareState <- sienaDependent(res1-mean(res1,na.rm=TRUE),type="continuous")

vdb<- sienaDataCreate(friends,sex,welfareState)
```

```{r}
vdb.eff <- getEffects(vdb)
vdb.eff <- includeEffects(vdb.eff, transTrip) 
#transtrip and transties likely result in colinearity. Shown by high rate parameters so only include one of the two
vdb.eff
```




```{r}
# Algorithm creation:
vdb.algo <- sienaAlgorithmCreate(projname = 'Project_practice', seed=123456)
```

```{r}
set.seed(123)
(ans0 <- siena07(vdb.algo, data=vdb, effects=vdb.eff,
                                                    returnDeps=TRUE))
```

The overall maximum convergence ratio is higher than 0.25, so we repeat the algorithm. 

```{r}
(ans1 <- siena07(vdb.algo, data=vdb, effects=vdb.eff,
                                                    prevAns=ans0))
```
#Main issue: large values of estimate and SE for rate
#use Jaccard index to keep track of network change. 
#stability of the network: individuals who are leaving the network? If so, include the info into RSiena
#other effects


---Experiment section with nacf 

-MVP: Network auto-correlation. nacf
https://www.rdocumentation.org/packages/sna/versions/2.7/topics/nacf

```{r}
set.seed(42)
#converting igraph object to statnent object
g1_1<-asNetwork(g1) #
```

#removed people who are loners in all six waves from wellbeing. Then did imputation.Graph is made from friend network, whic already went through loners removal
```{r}

interm<-wellbeing[,2] #slicing wellbeing1
y1=interm[-m2] #removing lonersxw
y1[is.na(y1)]<-mean(y1,na.rm=TRUE)
(y1)
nacf(g1_1,y=y1,type="moran",mode="digraph")[2]
#g1_1 has 21 vertices 

```
When high values repel other high values, and tend to be near low values, the Index will be negative.
Not auto-correlated
```{r}
nacf(g1_1,y=y1,type="geary",mode="digraph")[2]
```

Extremely positive. 
The value of geary C is 1 in the absence of spatial autocorrelation. A low value of C (0 < C < 1) represents a positive spatial autocorrelation and approaches zero for strong autocorrelation.
Not auto-correlated

#allowed to use mean imputation for now. 

#Issue is that wellbeing has two NA values.
#dataset of 21 not great
#focus on other classes? filter out classes with too many NA
```{r}
libary(spdep)
```


----
Referring to Geary's C formula
https://en.wikipedia.org/wiki/Geary%27s_C
https://link.springer.com/content/pdf/10.1007/s11749-018-0599-x.pdf

how can we tweak to handle missing values in x?
-tweak N value. N -> (N-# of actors with missing observed values in behavior)
-tweak the numerator of summation of i and j, s.t. i/j != the index of actors 
with missing observed values in behavior or network. 
-W is the sum of all w_ij of actors with present observed values

nacf:
function that takes one wellbeing vector and friendship adjacency matrix at one time point 
#make it more generalizable beyond wellbeing and friendship 
-finds ppl who did not participate in friendship
-finds ppl who did not participate in wellbeing 
-computes nacf 

































###Unimportant code for exploration 
```{r}
#df1<-merge(x = gender, y = wellbeing, by = "idcode",all.y=TRUE) #multiple wellbeing
#df1$gndr<-as.factor(df1$gndr) #1 male, 2 female
#ggplot(data=df1,aes(x=idcode,y=wellbeing1,fill=gndr))+geom_bar(stat='identity')
```









---Experiment section with visualization
https://igraph.org/r/doc/plot.common.html

https://cran.r-project.org/web/packages/sna/sna.pdf
#pg85 for garrow
#Pg81 for gplot
```{r}
#gplot(g2,edge.lwd=0.1)
#gplot(g2,edge.lwd=0.9)
#plot(g1, layout=l,rescale = FALSE, ylim=c(-4,4),xlim=c(-40,24), asp = 0)
#gplot.layout.kamadakawai(g2,layout.par = NULL)
```

```{r}
plot(g1)

V(g1)$size <- 7 #decreasing vertice size does not help make graph expand
V(g1)$label <- ""
V(g1)$arrow.size <- 0.001
V(g1)$arrow.width <- 0.001
l <- layout.kamada.kawai(g1)
#plot(g1, layout=l,rescale = FALSE, ylim=c(-4,4),xlim=c(-40,24), asp = 0)
plot(g1, layout=l,rescale = TRUE)

l <- layout.random(g1)
plot(g1, layout=l)

# Circle layout
l <- layout.circle(g1)
plot(g1, layout=l)
```

Currently, arrow size and width are held as constant so there's no way to change this. 

There is a hack around it, but it requires you drawing multiple plots manually. Here's a link with the instructions for basic igraph: https://stackoverflow.com/questions/16942553/a-hack-to-allow-arrows-size-in-r-igraph-to-match-edge-width

However, the hack example provided doesn't work itself